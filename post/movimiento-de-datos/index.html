<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    
    <meta itemprop="name" content="Movimiento de datos | Cutreblog">
    <meta itemprop="description" content="En este post veremos como realizar exportaciones e importaciones y trabajaremos con ellas.">

    
    <meta name="twitter:title" content="Movimiento de datos | Cutreblog">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:description" content="En este post veremos como realizar exportaciones e importaciones y trabajaremos con ellas.">
    <meta name="twitter:site" content="@ReeseCodes">
    <meta name="twitter:creator" content="@ReeseCodes">
    <meta name="twitter:image:src" content="https://reeseschultz.github.io/twitter.jpg">

    
    <meta name="og:title" content="Movimiento de datos | Cutreblog">
    <meta name="og:description" content="En este post veremos como realizar exportaciones e importaciones y trabajaremos con ellas.">
    <meta name="og:image" content="https://reeseschultz.github.io/og.jpg">
    <meta name="og:url" content="https://reeseschultz.github.io/">
    <meta name="og:site_name" content="Cutreblog">
    <meta name="og:locale" content="en_GB">
    <meta name="og:type" content="website">

    <link rel="icon" type="image/x-icon" href="/logo.png" />

    <title>Movimiento de datos | Cutreblog</title>

    <link rel="stylesheet" href="/assets/main.bundle.css">

    
  </head>
  <body class="flex flex-col min-h-screen">
    <header>
  <nav class="container mx-auto max-w-3xl px-8 pt-2 flex flex-wrap justify-between">
    <div>
      <h1>
        <a href="/">Cutreblog</a>
      </h1>
      <p>Blog de Alejandro Montes</p>
    </div>

    <ul class="flex flex-wrap sm:w-32 w-full mt-6 md:justify-between justify-evenly">
      <li>
        <a href="/404.html">404</a>
      </li>

      <li>
        <a href="/about">Sobre mí.</a>
      </li>
    </ul>
  </nav>
</header>

    <main class="container mx-auto max-w-3xl p-8 grow">
      
    <p></p>
    <div>
        <h2>Movimiento de datos</h2>

        
            <p class="excerpt">En este post veremos como realizar exportaciones e importaciones y trabajaremos con ellas.</p>
        

        
            <div class="mb-2">
                <a class="tag GBD" href="/tag/GBD">GBD</a>
            </div>
        

        
            
                <p class="text-sm italic">Creado en
                    <span datetime="Sat Feb 25 2023 01:00:00 GMT+0100 (hora estándar de Europa central)">February 25, 2023</span>.</p>
            
        

        <div class="content post">
            
                <hr />

                <h3>Tabla de Contenido.</h3>

                <nav class="toc">
                <ol>
                    
                    <li><a href="#realiza-una-exportaci%C3%B3n-del-esquema-de-scott-usando-oracle-data-pump-con-las-siguientes-condiciones%3A">Realiza una exportación del esquema de SCOTT usando Oracle Data Pump con las siguientes condiciones:</a>
            		</li>

                    <li><a href="#importa-el-fichero-obtenido-anteriormente-usando-oracle-data-pump-pero-en-un-usuario-distinto-de-la-misma-base-de-datos.">Importa el fichero obtenido anteriormente usando Oracle Data Pump pero en un usuario distinto de la misma base de datos.</a>
            		</li>

                    <li><a href="#realiza-una-exportaci%C3%B3n-de-la-estructura-de-todas-las-tablas-de-la-base-de-datos-usando-el-comando-expdp-de-oracle-data-pump-probando-al-menos-cinco-de-las-posibles-opciones-que-ofrece-dicho-comando-y-document%C3%A1ndolas-adecuadamente.">Realiza una exportación de la estructura de todas las tablas de la base de datos usando el comando expdp de Oracle Data Pump probando al menos cinco de las posibles opciones que ofrece dicho comando y documentándolas adecuadamente.</a>
            		</li>

                    <li><a href="#intenta-realizar-operaciones-similares-de-importaci%C3%B3n-y-exportaci%C3%B3n-con-las-herramientas-proporcionadas-con-mysql-desde-l%C3%ADnea-de-comandos%2C-documentando-el-proceso.">Intenta realizar operaciones similares de importación y exportación con las herramientas proporcionadas con MySQL desde línea de comandos, documentando el proceso.</a>
            		</li>

                    <li><a href="#intenta-realizar-operaciones-similares-de-importaci%C3%B3n-y-exportaci%C3%B3n-con-las-herramientas-proporcionadas-con-postgres-desde-l%C3%ADnea-de-comandos%2C-documentando-el-proceso.">Intenta realizar operaciones similares de importación y exportación con las herramientas proporcionadas con Postgres desde línea de comandos, documentando el proceso.</a>
            		</li>

                    <li><a href="#exporta-los-documentos-de-una-colecci%C3%B3n-de-mongodb-que-cumplan-una-determinada-condici%C3%B3n-e-imp%C3%B3rtalos-en-otra-base-de-datos.">Exporta los documentos de una colección de MongoDB que cumplan una determinada condición e impórtalos en otra base de datos.</a>
            		</li>

                    <li><a href="#sqlloader-es-una-herramienta-que-sirve-para-cargar-grandes-vol%C3%BAmenes-de-datos-en-una-instancia-de-oracle.-exportad-los-datos-de-una-base-de-datos-completa-desde-postgres-a-texto-plano-con-delimitadores-y-emplead-sqlloader-para-realizar-el-proceso-de-carga-de-dichos-datos-a-una-instancia-oracle.-deb%C3%A9is-documentar-todo-el-proceso%2C-explicando-los-distintos-ficheros-de-configuraci%C3%B3n-y-de-log-que-tiene-sqlloader.">SQLLoader es una herramienta que sirve para cargar grandes volúmenes de datos en una instancia de ORACLE. Exportad los datos de una base de datos completa desde Postgres a texto plano con delimitadores y emplead SQLLoader para realizar el proceso de carga de dichos datos a una instancia ORACLE. Debéis documentar todo el proceso, explicando los distintos ficheros de configuración y de log que tiene SQLLoader.</a>
            		</li>
                </ol>
            </nav>

                <hr />
            

            <h3 id="realiza-una-exportaci%C3%B3n-del-esquema-de-scott-usando-oracle-data-pump-con-las-siguientes-condiciones%3A" tabindex="-1">Realiza una exportación del esquema de SCOTT usando Oracle Data Pump con las siguientes condiciones:</h3>
<ul>
<li><strong>Exporta tanto la estructura de las tablas como los datos de las mismas.</strong></li>
<li><strong>Excluye la tabla BONUS y los departamentos con menos de dos empleados.</strong></li>
<li><strong>Realiza una estimación previa del tamaño necesario para el fichero de exportación.</strong></li>
<li><strong>Programa la operación para dentro de 2 minutos.</strong></li>
<li><strong>Genera un archivo de log en el directorio raíz.</strong></li>
</ul>
<p>Lo primero que haremos será crear un directorio donde se guardará la exportación:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~$ sudo mkdir /opt/oracle/export</code></pre>
<p>Ahora nos conectamos con un usuario con privilegios y creamos un directorio objeto en la base de datos, le damos permiso de lectura y escritura en el directorio y le damos privilegios para que pueda exportar:</p>
<pre class="language-txt"><code class="language-txt">SQL> CREATE DIRECTORY BD_EXPORT AS '/opt/oracle/export';<br><br>Directorio creado.<br><br>SQL> GRANT READ,WRITE ON DIRECTORY BD_EXPORT TO SCOTT;<br><br>Concesion terminada correctamente.<br><br><br>SQL> GRANT  DATAPUMP_EXP_FULL_DATABASE TO SCOTT;<br><br>Concesion terminada correctamente.<br></code></pre>
<p>Ejecutamos el siguiente comando para ver la estimación del tamaño del fichero de exportación:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~$ expdp scott/TIGER schemas=scott exclude=table:\"IN \(\'BONUS\'\)\" directory=BD_EXPORT ESTIMATE_ONLY=YES<br><br>Export: Release 19.0.0.0.0 - Production on Sun Feb 26 16:23:01 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production<br><br>Advertencia: Las operaciones de Oracle Data Pump no se necesitan normalmente cuando se conecta a la raiz o al elemento inicial de una base de datos del contenedor.<br><br>Iniciando "SCOTT"."SYS_EXPORT_SCHEMA_01":  scott/******** schemas=scott exclude=table:"IN ('BONUS')" directory=BD_EXPORT ESTIMATE_ONLY=YES <br>Estimacion en curso mediante el metodo BLOCKS...<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/TABLE_DATA<br>.  estimado "SCOTT"."EMP"                                 896 MB<br>.  estimado "SCOTT"."DEPT"                                 64 KB<br>Estimacion total mediante el metodo BLOCKS: 896.0 MB<br>El trabajo "SCOTT"."SYS_EXPORT_SCHEMA_01" ha terminado correctamente en Dom Feb 26 16:23:10 2023 elapsed 0 00:00:08<br><br></code></pre>
<p>Creamos un script para realizar la exportación y lo ejecutamos:</p>
<pre class="language-txt"><code class="language-txt">echo "La exportación se realizará en 2 minutos..."<br>sleep 120<br>expdp scott/TIGER schemas=scott exclude=table:\"IN \(\'BONUS\'\)\" directory=BD_EXPORT dumpfile=SCOTT.dmp logfile=SCOTT.log<br></code></pre>
<p>Lo ejecutamos:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~$ ./export.sh <br>La exportación se realizará en 2 minutos...<br><br>Export: Release 19.0.0.0.0 - Production on Sat Feb 25 21:09:00 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production<br><br>Advertencia: Las operaciones de Oracle Data Pump no se necesitan normalmente cuando se conecta a la raiz o al elemento inicial de una base de datos del contenedor.<br><br>Iniciando "SCOTT"."SYS_EXPORT_SCHEMA_01":  scott/******** schemas=scott exclude=table:"IN ('BONUS')" directory=BD_EXPORT dumpfile=SCOTT.dmp logfile=SCOTT.log <br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/TABLE_DATA<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS<br>Procesando el tipo de objeto SCHEMA_EXPORT/STATISTICS/MARKER<br>Procesando el tipo de objeto SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/TABLE<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/COMMENT<br>Procesando el tipo de objeto SCHEMA_EXPORT/PROCEDURE/PROCEDURE<br>Procesando el tipo de objeto SCHEMA_EXPORT/PROCEDURE/ALTER_PROCEDURE<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/INDEX/INDEX<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/CONSTRAINT/REF_CONSTRAINT<br>. . "SCOTT"."EMP"                               22.41 KB      14 filas exportadas<br>. . "SCOTT"."DEPT"                              6.046 KB       5 filas exportadas<br>La tabla maestra "SCOTT"."SYS_EXPORT_SCHEMA_01" se ha cargado/descargado correctamente<br>******************************************************************************<br>El juego de archivos de volcado para SCOTT.SYS_EXPORT_SCHEMA_01 es:<br>  /opt/oracle/export/SCOTT.dmp<br>El trabajo "SCOTT"."SYS_EXPORT_SCHEMA_01" ha terminado correctamente en Sab Feb 25 21:09:14 2023 elapsed 0 00:00:13<br></code></pre>
<p>No he podido excluir los departamentos con menos de dos empleados debido a que usando el parámetro query e indicando que para la tabla dept coja los que tienen más de dos empleados, no me funcionaba. Adjunto el parámetro query y su contenido:</p>
<pre class="language-txt"><code class="language-txt">query=DEPT:\"WHERE \(SELECT COUNT\(*\) FROM EMP WHERE EMP.DEPTNO = DEPT.DEPTNO\) \> 1\"</code></pre>
<h3 id="importa-el-fichero-obtenido-anteriormente-usando-oracle-data-pump-pero-en-un-usuario-distinto-de-la-misma-base-de-datos." tabindex="-1">Importa el fichero obtenido anteriormente usando Oracle Data Pump pero en un usuario distinto de la misma base de datos.</h3>
<p>Primero le damos permisos de lectura y escritura sobre el directorio donde está almacenada la exportación al usuario en el que la importaremos:</p>
<pre class="language-txt"><code class="language-txt">SQL> GRANT READ, WRITE ON DIRECTORY BD_EXPORT TO alemd;<br><br>Concesion terminada correctamente.<br></code></pre>
<p>Antes de realizar la importación, al usuario en el cual la realizaremos, le concederemos privilegios sobre importación:</p>
<pre class="language-txt"><code class="language-txt">SQL> GRANT IMP_FULL_DATABASE TO alemd;<br><br>Concesion terminada correctamente.<br></code></pre>
<p>Con el comando impdp importaremos la exportación realizada anteriormente:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~$ impdp alemd/usuario schemas=SCOTT directory=BD_EXPORT dumpfile=SCOTT.dmp logfile=SCOTTimport.log <br><br>Import: Release 19.0.0.0.0 - Production on Sun Feb 26 13:37:10 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production<br><br>Advertencia: Las operaciones de Oracle Data Pump no se necesitan normalmente cuando se conecta a la raiz o al elemento inicial de una base de datos del contenedor.<br><br>La tabla maestra "ALEMD"."SYS_IMPORT_SCHEMA_01" se ha cargado/descargado correctamente<br>Iniciando "ALEMD"."SYS_IMPORT_SCHEMA_01":  alemd/******** schemas=SCOTT directory=BD_EXPORT dumpfile=SCOTT.dmp logfile=SCOTTimport.log <br>Procesando el tipo de objeto SCHEMA_EXPORT/ROLE_GRANT<br>Procesando el tipo de objeto SCHEMA_EXPORT/DEFAULT_ROLE<br>Procesando el tipo de objeto SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/TABLE<br>ORA-39151: La tabla "SCOTT"."EMP" existe. Todos los metadados dependientes y los datos se omitiran debido table_exists_action de omitir<br><br>ORA-39151: La tabla "SCOTT"."DEPT" existe. Todos los metadados dependientes y los datos se omitiran debido table_exists_action de omitir<br><br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/TABLE_DATA<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/FGA_POLICY<br>ORA-39083: Fallo de creacion del tipo de objeto FGA_POLICY con el error:<br>ORA-28101: la politica ya existe<br><br>El sql que falla es:<br>BEGIN DBMS_FGA.ADD_POLICY('SCOTT','EMP','POLICY_EJ4','SAL > 2000','','','',TRUE,'INSERT',DBMS_FGA.DB_EXTENDED,DBMS_FGA.ANY_COLUMNS,'SYS'); END;<br><br>Procesando el tipo de objeto SCHEMA_EXPORT/PROCEDURE/PROCEDURE<br>ORA-31684: El tipo de objeto PROCEDURE:"SCOTT"."ADD_10000_EMP" ya existe<br><br>ORA-31684: El tipo de objeto PROCEDURE:"SCOTT"."ADD_100000_EMP" ya existe<br><br>Procesando el tipo de objeto SCHEMA_EXPORT/PROCEDURE/ALTER_PROCEDURE<br>ORA-39111: Se ha saltado el tipo de objeto dependiente ALTER_PROCEDURE:"SCOTT"."ADD_100000_EMP", ya existe el tipo de objeto base PROCEDURE:"SCOTT"."ADD_100000_EMP"<br><br>ORA-39111: Se ha saltado el tipo de objeto dependiente ALTER_PROCEDURE:"SCOTT"."ADD_10000_EMP", ya existe el tipo de objeto base PROCEDURE:"SCOTT"."ADD_10000_EMP"<br><br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/INDEX/INDEX<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/CONSTRAINT/REF_CONSTRAINT<br>Procesando el tipo de objeto SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS<br>Procesando el tipo de objeto SCHEMA_EXPORT/STATISTICS/MARKER<br>El trabajo "ALEMD"."SYS_IMPORT_SCHEMA_01" ha terminado con 7 error(es) en Dom Feb 26 13:37:19 2023 elapsed 0 00:00:08<br></code></pre>
<p>Salen errores, porque no es el primer intento con ese usuario y se han duplicado cosas. A continuación nos conectaremos con el usuario y realizaremos una consulta a la tabla DEPT.</p>
<pre class="language-txt"><code class="language-txt">SQL> SELECT DNAME FROM SCOTT.DEPT;<br><br>DNAME<br>--------------<br>PRUEBA<br>ACCOUNTING<br>RESEARCH<br>SALES<br>OPERATIONS<br></code></pre>
<p>Tenemos que indicar el esquema al consultar la tabla debido a que hemos realizado la exportación del esquema y al realizar la importación, el esquema se ha importado.</p>
<h3 id="realiza-una-exportaci%C3%B3n-de-la-estructura-de-todas-las-tablas-de-la-base-de-datos-usando-el-comando-expdp-de-oracle-data-pump-probando-al-menos-cinco-de-las-posibles-opciones-que-ofrece-dicho-comando-y-document%C3%A1ndolas-adecuadamente." tabindex="-1">Realiza una exportación de la estructura de todas las tablas de la base de datos usando el comando expdp de Oracle Data Pump probando al menos cinco de las posibles opciones que ofrece dicho comando y documentándolas adecuadamente.</h3>
<p>La exportación la realizo usando el siguiente comando:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~$ expdp system/usuario DIRECTORY=BD_EXPORT DUMPFILE=full_export.dmp FULL=YES CONTENT=METADATA_ONLY exclude=table:\"IN \(\'SCOTT.DEPT\'\)\" <br><br>Export: Release 19.0.0.0.0 - Production on Sun Feb 26 16:29:46 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production<br><br>Advertencia: Las operaciones de Oracle Data Pump no se necesitan normalmente cuando se conecta a la raiz o al elemento inicial de una base de datos del contenedor.<br><br>Iniciando "SYSTEM"."SYS_EXPORT_FULL_01":  system/******** DIRECTORY=BD_EXPORT DUMPFILE=full_export.dmp FULL=YES CONTENT=METADATA_ONLY exclude=table:"IN ('SCOTT.DEPT')" <br>Procesando el tipo de objeto DATABASE_EXPORT/EARLY_OPTIONS/VIEWS_AS_TABLES/TABLE_DATA<br>Procesando el tipo de objeto DATABASE_EXPORT/NORMAL_OPTIONS/TABLE_DATA<br>Procesando el tipo de objeto DATABASE_EXPORT/NORMAL_OPTIONS/VIEWS_AS_TABLES/TABLE_DATA<br><br>.<br>.<br>.<br>.<br>.<br><br>La tabla maestra "SYSTEM"."SYS_EXPORT_FULL_01" se ha cargado/descargado correctamente<br>******************************************************************************<br>El juego de archivos de volcado para SYSTEM.SYS_EXPORT_FULL_01 es:<br>  /opt/oracle/export/full_export.dmp<br>El trabajo "SYSTEM"."SYS_EXPORT_FULL_01" ha terminado correctamente en Dom Feb 26 16:36:18 2023 elapsed 0 00:06:31<br></code></pre>
<p>Ahora, explicaré todos los parámetros usados:</p>
<ul>
<li>
<p>DIRECTORY: Con este parámetro indicamos el directorio donde se guardará el dump, como vemos indica BD_EXPORT, esto lo hemos creados desde la terminal de sqlplus con el <code>CREATE DIRECTORY</code>, que indicamos un nombre del directorio y la ruta.</p>
</li>
<li>
<p>DUMPFILE: Es el nombre del archivo donde se guarda la exportación.</p>
</li>
<li>
<p>FULL: Indicamos que la exportación es de la base de datos al completo.</p>
</li>
<li>
<p>CONTENT: Con este parámetro, indicamos el contenido. Podemos indicar ALL que es por defecto e indica todo el contenido, DATA_ONLY solo guarda datos y METADATA_ONLY solo guarda metadatos como la estructúras de tablas.</p>
</li>
<li>
<p>EXCLUDE: Con este parámetros indicamos lo que queremos excluir, ya sea a través de una expresión regular, una tabla, un esquema…</p>
</li>
</ul>
<h3 id="intenta-realizar-operaciones-similares-de-importaci%C3%B3n-y-exportaci%C3%B3n-con-las-herramientas-proporcionadas-con-mysql-desde-l%C3%ADnea-de-comandos%2C-documentando-el-proceso." tabindex="-1">Intenta realizar operaciones similares de importación y exportación con las herramientas proporcionadas con MySQL desde línea de comandos, documentando el proceso.</h3>
<p>Vamos a realizar una exportación de la base de datos SCOTT y la importaremos en una base de datos llamada import:</p>
<pre class="language-txt"><code class="language-txt">root@debian:/home/usuario# mysqldump -u root SCOTT > mariadbexport.sql<br>root@debian:/home/usuario# ls<br>alemd.key  gonzalonazareno.crt	PRACTICA_DOCKER<br>docker	   mariadbexport.sql</code></pre>
<p>Con este comando, hemos exportado la base de datos SCOTT al fichero mariadbexport.sql. Ahora Crearemos una base de datos totalmente limpia llamada import que es donde importaremos el dump.</p>
<pre class="language-txt"><code class="language-txt">MariaDB [(none)]> CREATE DATABASE IMPORT_SCOTT;<br>Query OK, 1 row affected (0,001 sec)<br><br>MariaDB [(none)]> EXIT<br>Bye</code></pre>
<p>Ahora ejecutamos el siguiente comando para importar los datos:</p>
<pre class="language-txt"><code class="language-txt">root@debian:/home/usuario# mysql -u root IMPORT_SCOTT &lt; mariadbexport.sql</code></pre>
<p>Nos conectamos a la base de datos y mostramos que se han creado las tablas correctamente:</p>
<pre class="language-txt"><code class="language-txt">root@debian:/home/usuario# mysql<br>Welcome to the MariaDB monitor.  Commands end with ; or \g.<br>Your MariaDB connection id is 35<br>Server version: 10.5.18-MariaDB-0+deb11u1 Debian 11<br><br>Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.<br><br>Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.<br><br>MariaDB [(none)]> use IMPORT_SCOTT<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A<br><br>Database changed<br>MariaDB [IMPORT_SCOTT]> show tables;<br>+------------------------+<br>| Tables_in_IMPORT_SCOTT |<br>+------------------------+<br>| DEPT                   |<br>| EMP                    |<br>+------------------------+<br>2 rows in set (0,000 sec)</code></pre>
<p>Ahora realizaré una consulta para probar que los datos están insertados correctamente:</p>
<pre class="language-txt"><code class="language-txt">MariaDB [IMPORT_SCOTT]> SELECT * FROM DEPT;<br>+--------+------------+----------+<br>| DEPTNO | DNAME      | LOC      |<br>+--------+------------+----------+<br>|     10 | ACCOUNTING | NEW YORK |<br>|     20 | RESEARCH   | DALLAS   |<br>|     30 | SALES      | CHICAGO  |<br>|     40 | OPERATIONS | BOSTON   |<br>+--------+------------+----------+<br>4 rows in set (0,001 sec)<br></code></pre>
<h3 id="intenta-realizar-operaciones-similares-de-importaci%C3%B3n-y-exportaci%C3%B3n-con-las-herramientas-proporcionadas-con-postgres-desde-l%C3%ADnea-de-comandos%2C-documentando-el-proceso." tabindex="-1">Intenta realizar operaciones similares de importación y exportación con las herramientas proporcionadas con Postgres desde línea de comandos, documentando el proceso.</h3>
<p>En nuestra base de datos postgres, tenemos la base de datos de un aeropuerto, y procederemos a realizar una exportación:</p>
<pre class="language-txt"><code class="language-txt">postgres@PostgreSQL:~$ pg_dump -U postgres aeropuerto > aeropuertodump.sql<br>postgres@PostgreSQL:~$ ls<br>11  aeropuertodump.sql	instantclient_21_1  oracle_fdw	PG_11_201809051</code></pre>
<p>Ahora lo importaremos en la base de datos import_aeropuerto:</p>
<pre class="language-txt"><code class="language-txt">postgres@PostgreSQL:~$ psql -U postgres -d import_aeropuerto &lt; aeropuertodump.sql <br>SET<br>SET<br>SET<br>SET<br>SET<br> set_config <br>------------<br> <br>(1 fila)<br><br>SET<br>SET<br>SET<br>SET<br>CREATE FUNCTION<br>ALTER FUNCTION<br>CREATE FUNCTION<br>ALTER FUNCTION<br>SET<br>SET<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>CREATE TABLE<br>ALTER TABLE<br>COPY 8<br>COPY 6<br>COPY 6<br>COPY 20<br>COPY 3<br>COPY 4<br>COPY 10<br>COPY 18<br>COPY 12<br>COPY 3<br>COPY 12<br>COPY 5<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>CREATE TRIGGER<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>ALTER TABLE<br>GRANT<br></code></pre>
<p>Nos conectamos a la base de datos y mostramos que se ha importado correctamente:</p>
<pre class="language-txt"><code class="language-txt">postgres@PostgreSQL:~$ psql<br>psql (11.17 (Debian 11.17-0+deb10u1))<br>Digite «help» para obtener ayuda.<br><br>postgres=# \c import_aeropuerto<br>Ahora está conectado a la base de datos «import_aeropuerto» con el usuario «postgres».<br>import_aeropuerto=# \d<br>              Listado de relaciones<br> Esquema |       Nombre        | Tipo  |  Dueño   <br>---------+---------------------+-------+----------<br> public  | aeronaves           | tabla | postgres<br> public  | aeropuertos         | tabla | postgres<br> public  | auxiliares          | tabla | postgres<br> public  | auxiliaresdeviaje   | tabla | postgres<br> public  | copilotos           | tabla | postgres<br> public  | modelos             | tabla | postgres<br> public  | pasajeros           | tabla | postgres<br> public  | pasajerosembarcados | tabla | postgres<br> public  | personal            | tabla | postgres<br> public  | pilotos             | tabla | postgres<br> public  | viajes              | tabla | postgres<br> public  | vuelos              | tabla | postgres<br>(12 filas)<br></code></pre>
<p>Hacemos una consulta a la tabla pilotos:</p>
<pre class="language-txt"><code class="language-txt">import_aeropuerto=# select * from pilotos;<br> numpasaporte <br>--------------<br> CVF000126<br> DSA000777<br> EJK000333<br>(3 filas)<br></code></pre>
<h3 id="exporta-los-documentos-de-una-colecci%C3%B3n-de-mongodb-que-cumplan-una-determinada-condici%C3%B3n-e-imp%C3%B3rtalos-en-otra-base-de-datos." tabindex="-1">Exporta los documentos de una colección de MongoDB que cumplan una determinada condición e impórtalos en otra base de datos.</h3>
<p>Tenemos una colección con algunos restaurantes de estados unidos. Vamos a exportar los restaurantes que sean del barrio del Bronx y de tipo de comida Americana:</p>
<pre class="language-txt"><code class="language-txt">root@mongodb:/home/vagrant# mongoexport -u admin --db admin --collection restaurants -q "{ \"borough\": \"Bronx\", \"cuisine\": \"American\" }" --out restaurantes_americanos_bronx.json<br>Enter password for mongo user:<br><br>2023-02-26T18:43:11.396+0000	connected to: mongodb://localhost/<br>2023-02-26T18:43:11.524+0000	exported 822 records<br>root@mongodb:/home/vagrant# ls<br>primer-dataset.json  restaurantes_americanos_bronx.json</code></pre>
<p>Ahora lo importaremos en una base de datos llamada prueba:</p>
<pre class="language-txt"><code class="language-txt">root@mongodb:/home/vagrant# mongoimport -u alemd --db prueba --collection restaurants --file restaurantes_americanos_bronx.json<br>Enter password for mongo user:<br><br>2023-02-26T19:01:51.176+0000	connected to: mongodb://localhost/<br>2023-02-26T19:01:51.777+0000	822 document(s) imported successfully. 0 document(s) failed to import.</code></pre>
<p>Nos conectamos y haremos una consulta para ver que funciona:</p>
<pre class="language-txt"><code class="language-txt">root@mongodb:/home/vagrant# mongosh -u alemd -p --authenticationDatabase prueba<br>Enter password: *******<br>Current Mongosh Log ID:	63fbacdc88222b513ba0b957<br>Connecting to:		mongodb://&lt;credentials>@127.0.0.1:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000&amp;authSource=prueba&amp;appName=mongosh+1.7.1<br>Using MongoDB:		6.0.4<br>Using Mongosh:		1.7.1<br><br>For mongosh info see: https://docs.mongodb.com/mongodb-shell/<br><br>Enterprise test> use prueba<br>switched to db prueba<br>Enterprise prueba> db.restaurants.findOne()<br>{<br>  _id: ObjectId("63fba382a0e597287f628a4a"),<br>  address: {<br>    building: '2300',<br>    coord: [ -73.8786113, 40.8502883 ],<br>    street: 'Southern Boulevard',<br>    zipcode: '10460'<br>  },<br>  borough: 'Bronx',<br>  cuisine: 'American',<br>  grades: [<br>    {<br>      date: ISODate("2014-05-28T00:00:00.000Z"),<br>      grade: 'A',<br>      score: 11<br>    },<br>    { date: ISODate("2013-06-19T00:00:00.000Z"), grade: 'A', score: 4 },<br>    { date: ISODate("2012-06-15T00:00:00.000Z"), grade: 'A', score: 3 }<br>  ],<br>  name: 'Wild Asia',<br>  restaurant_id: '40357217'<br>}</code></pre>
<h3 id="sqlloader-es-una-herramienta-que-sirve-para-cargar-grandes-vol%C3%BAmenes-de-datos-en-una-instancia-de-oracle.-exportad-los-datos-de-una-base-de-datos-completa-desde-postgres-a-texto-plano-con-delimitadores-y-emplead-sqlloader-para-realizar-el-proceso-de-carga-de-dichos-datos-a-una-instancia-oracle.-deb%C3%A9is-documentar-todo-el-proceso%2C-explicando-los-distintos-ficheros-de-configuraci%C3%B3n-y-de-log-que-tiene-sqlloader." tabindex="-1">SQLLoader es una herramienta que sirve para cargar grandes volúmenes de datos en una instancia de ORACLE. Exportad los datos de una base de datos completa desde Postgres a texto plano con delimitadores y emplead SQLLoader para realizar el proceso de carga de dichos datos a una instancia ORACLE. Debéis documentar todo el proceso, explicando los distintos ficheros de configuración y de log que tiene SQLLoader.</h3>
<p>Lo primero que haremos será en postgres exportar la base de datos del aeropuerto como un archivo csv delimitado por coma. Para ello, he creado un procedimiento que me creará por cada tabla de la base de datos un fichero csv con los datos de cada tabla:</p>
<pre class="language-txt"><code class="language-txt">postgres=# CREATE OR REPLACE FUNCTION exportar_tablas_a_csv(<br>    _nombre_de_la_base_de_datos TEXT,<br>    _ruta TEXT<br>)<br>RETURNS VOID AS $$<br>DECLARE<br>    _nombre_de_la_tabla TEXT;<br>BEGIN<br>    FOR _nombre_de_la_tabla IN<br>        SELECT table_name<br>        FROM information_schema.tables<br>        WHERE table_schema = 'public'<br>        AND table_type = 'BASE TABLE'<br>    LOOP<br>        EXECUTE format(<br>            'COPY %I TO %L WITH (FORMAT CSV, DELIMITER ",", HEADER)',<br>            _nombre_de_la_tabla,<br>            _ruta || _nombre_de_la_tabla || '.csv'<br>        );<br>    END LOOP;<br>END;<br>$$ LANGUAGE plpgsql;<br>CREATE FUNCTION<br></code></pre>
<p>Ahora ejecutamos el procedimiento:</p>
<pre class="language-txt"><code class="language-txt">aeropuerto=# SELECT exportar_tablas_a_csv('SCOTT', '/var/lib/postgresql/');<br> exportar_tablas_a_csv <br>-----------------------<br> <br>(1 fila)<br></code></pre>
<p>Como vemos, tenemos las tablas emp y dept en ficheros csv:</p>
<pre class="language-txt"><code class="language-txt">postgres@PostgreSQL:~$ ls<br>11	    dept.csv  instantclient_21_1  PG_11_201809051<br>aeropuerto  emp.csv   oracle_fdw<br></code></pre>
<p>Ahora creamos los archivos de control que usaremos para importar cada tabla:</p>
<pre class="language-txt"><code class="language-txt">OPTIONS (SKIP=1)<br>LOAD DATA<br>INFILE '/home/alemd/oracle/dept.csv'<br>INTO TABLE DEPT<br>FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'<br>TRAILING NULLCOLS<br>(deptno, DNAME, LOC)</code></pre>
<p>Ahora muestro el fichero de control de la tabla emp:</p>
<pre class="language-txt"><code class="language-txt">OPTIONS (SKIP=1)<br>LOAD DATA<br>INFILE '/home/alemd/oracle/emp.csv'<br>INTO TABLE emp<br>FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'<br>TRAILING NULLCOLS<br>(<br>    EMPNO,<br>    ENAME,<br>    JOB,<br>    MGR,<br>    HIREDATE DATE "YYYY-MM-DD HH24:MI:SS",<br>    SAL DECIMAL(7,2),<br>    COMM DECIMAL(7,2),<br>    DEPTNO<br>)<br></code></pre>
<p>La opción skip=1, hace que no inserte la primera fila, que en el fichero csv sería el nombre de las columnas, con load data indicamos que cargue los datos desde el archivo emp.csv a la tabla emp y está separado por una coma y opcionalmente cerrado por una comilla doble. Por último, indicamos el nombre de las columnas, y si necesita algún formato concreto como una fecha o un número decimal.</p>
<p>Ejecutamos el sql loader para la tabla dept, como vemos se han cargado correctamente los datos.</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~/oracle$ sqlldr SCOTT/TIGER control=/home/alemd/oracle/dept.ctl log=/home/alemd/oracle/dept.log<br><br>SQL*Loader: Release 19.0.0.0.0 - Production on Mon Feb 27 00:15:41 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Path used:      Conventional<br>Commit point reached - logical record count 4<br><br>Table DEPT:<br>  4 Rows successfully loaded.<br><br>Check the log file:<br>  /home/alemd/oracle/dept.log<br>for more information about the load.</code></pre>
<p>Para la tabla EMP no averiguo porque no funciona, creo que el problema viene de los números decimales. Ahora veremos el log:</p>
<pre class="language-txt"><code class="language-txt">alemd@debian:~/oracle$ cat dept.log <br><br>SQL*Loader: Release 19.0.0.0.0 - Production on Mon Feb 27 00:15:41 2023<br>Version 19.3.0.0.0<br><br>Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.<br><br>Control File:   /home/alemd/oracle/dept.ctl<br>Data File:      /home/alemd/oracle/dept.csv<br>  Bad File:     /home/alemd/oracle/dept.bad<br>  Discard File:  none specified<br> <br> (Allow all discards)<br><br>Number to load: ALL<br>Number to skip: 1<br>Errors allowed: 50<br>Bind array:     250 rows, maximum of 1048576 bytes<br>Continuation:    none specified<br>Path used:      Conventional<br><br>Table DEPT, loaded from every logical record.<br>Insert option in effect for this table: INSERT<br>TRAILING NULLCOLS option in effect<br><br>   Column Name                  Position   Len  Term Encl Datatype<br>------------------------------ ---------- ----- ---- ---- ---------------------<br>DEPTNO                              FIRST     *   ,  O(") CHARACTER            <br>DNAME                                NEXT     *   ,  O(") CHARACTER            <br>LOC                                  NEXT     *   ,  O(") CHARACTER            <br><br><br>Table DEPT:<br>  4 Rows successfully loaded.<br>  0 Rows not loaded due to data errors.<br>  0 Rows not loaded because all WHEN clauses were failed.<br>  0 Rows not loaded because all fields were null.<br><br><br>Space allocated for bind array:                 193500 bytes(250 rows)<br>Read   buffer bytes: 1048576<br><br>Total logical records skipped:          1<br>Total logical records read:             4<br>Total logical records rejected:         0<br>Total logical records discarded:        0<br><br>Run began on Mon Feb 27 00:15:41 2023<br>Run ended on Mon Feb 27 00:15:41 2023<br><br>Elapsed time was:     00:00:00.10<br>CPU time was:         00:00:00.03<br></code></pre>
<p>Este log indica que en la tabla dept hemos tenido 4 filas cargadas correctamente.</p>
<hr>
<h2 id="documento-realizado-por%3A" tabindex="-1"><strong>Documento realizado por:</strong></h2>
<p>✒️ <strong>Alejandro Montes Delgado</strong> - <em>2º ASIR</em></p>

        </div>
            <p class="uppercase text-xs mt-6">Post anterior.</p>

            <p class="font-bold">
                <a href="/post/ejercicios-de-k8s-vii./">Ejercicios de K8s VII.</a>
            </p>
        
    </div>

    </main>
    <footer class="bg-gray-900 pb-10">
  <p class="block text-center text-sm mb-6">
    Built by
    <a target="_blank" href="https://github.com/reeseschultz">
      Reese Schultz
    </a>
  </p>

  <a class="block text-center text-sm" href="/privacy-policy">Privacy Policy</a>
</footer>
    <script src="https://unpkg.com/clipboard@2/dist/clipboard.min.js"></script>
    <script src="/assets/main.bundle.js"></script>
  </body>
</html>
